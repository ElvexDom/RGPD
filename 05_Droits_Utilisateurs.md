# Droits des utilisateurs autour de l'IA

## Objectif

Ce document explique comment les utilisateurs peuvent exercer leurs **droits sur leurs données personnelles** utilisées par des systèmes d’IA, notamment pour l’entraînement de modèles génératifs.  
Il synthétise les recommandations de la **CNIL** et fournit des exemples pratiques selon les plateformes.

---

## 1. Contexte

- Les agents conversationnels (chatbots, IA génératives, assistants vocaux) peuvent réutiliser les **données personnelles** des utilisateurs pour améliorer leurs modèles.  
- Le **RGPD** impose que toute utilisation de données personnelles soit encadrée, y compris pour le développement de l’IA.  
- La CNIL fournit des moyens concrets pour exercer le **droit d’opposition** et reprendre le contrôle sur l’usage de ses données.

**Ce droit concerne notamment :**

- Conversations échangées avec l’IA  
- Publications ou contenus accessibles publiquement  
- Informations issues de comptes utilisateurs  
- Interactions via des services utilisant l’IA  

> Le développement de l’IA **n’autorise pas l’utilisation illimitée des données**.

---

## 2. Vos droits selon la CNIL

### Droit d’opposition

- Toute personne peut s’opposer à l’utilisation de ses données pour entraîner un modèle d’IA.  
- **Actions possibles :**  
  - Contacter directement le fournisseur d’IA pour exercer ce droit  
  - Utiliser les paramètres dédiés pour désactiver l’usage des données  
  - Passer par des formulaires officiels lorsque nécessaire  

> La CNIL ne juge pas la légalité des pratiques, mais fournit les moyens d’agir concrètement.

---

## 3. Exemples pratiques selon les plateformes

### OpenAI / ChatGPT

- Paramètres de confidentialité disponibles dans les contrôles de données.  
- Possibilité de **désactiver l’usage des conversations pour l’entraînement**.  
- Lien : [OpenAI Privacy Settings](https://platform.openai.com/account/data-controls)

### Meta (Facebook, Instagram)

- Formulaire dédié pour **refuser l’usage de ses données**, même sans compte.  
- Lien : [Meta Opt-Out Form](https://www.meta.com/privacy/opt-out/)

### LinkedIn

- Paramètre « Données pour l’amélioration de l’IA générative » permettant de refuser la réutilisation.  
- Lien : [LinkedIn AI Data Settings](https://www.linkedin.com/help/linkedin/answer/127150)

### Autres IA (Mistral, Claude, Grok…)

- Options similaires dans les paramètres : « Amélioration du modèle », « Utiliser mes données », « Entraînement du modèle ».  
- Il est conseillé de vérifier régulièrement les paramètres, car les services d’IA mettent à jour leurs réglages de confidentialité.

---

## 4. Implications pratiques

1. **Agir rapidement**  
   - Une fois les données utilisées pour l’entraînement, il devient difficile voire impossible de les retirer.  
   - Exercer son droit **avant l’usage** est essentiel.

2. **Vérifier régulièrement les paramètres**  
   - Les services d’IA changent leurs réglages, il est conseillé de surveiller périodiquement.

3. **Rappel du droit RGPD**  
   - Ce droit n’est pas optionnel : l’utilisateur peut exiger que ses données **ne soient pas utilisées pour l’IA**.

---

## 5. Points clés à retenir

- Le RGPD encadre fortement les pratiques d’IA.  
- Les acteurs IA doivent fournir des mécanismes d’opposition **visibles et accessibles**.  
- La CNIL adapte les principes de protection des données aux technologies émergentes.

---

## 6. Sources et références

- [CNIL – Droit d’opposition IA](https://www.cnil.fr/fr/ia-comment-sopposer-la-reutilisation-de-ses-donnees-personnelles-entrainement-agent-conversationnel)
- [OpenAI Privacy Settings](https://platform.openai.com/account/data-controls)  
- [Meta Opt-Out Form](https://www.meta.com/privacy/opt-out/)  
- [LinkedIn AI Data Settings](https://www.linkedin.com/help/linkedin/answer/127150)  
- [CNIL – Recommandations RGPD et IA](https://www.cnil.fr/sites/cnil/files/2024-04/recommandation_sur_l_application_du_rgpd_au_developpement_des_systemes_d_intelligence_artificielle_1.pdf)  

---

[⬅ Retour à la page principale](00_Veille_RGPD_IA.md)
